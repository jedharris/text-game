# Structured Action Reports Design

## Overview

This document analyzes the proposal from GitHub issue #215: replacing handler-generated prose with fully structured action data, allowing the LLM to synthesize all natural language.

**Related Documents:**
- `game_engine_narration_api_design.md` — Current target architecture
- `narration_api_implementation_plan.md` — Ongoing refactor plan
- `unified_narrator_prompt_revised_api.md` — Current narrator prompt

**Constraints:**
- Small local model (~3B parameters, e.g., Llama 3.2 3B)
- Fast interaction required
- Prompt is cached; context reset after each turn

---

## Key Insight: Fragment-Based Approach

Looking at `examples/fancy_game/game_state.json`, the existing `llm_context` pattern already provides the model:

1. **traits** — Short sensory/descriptive phrases: `"pitted blade"`, `"cold to touch"`, `"creaks when moved"`
2. **state_variants** — Pre-authored fragments keyed by state:
   ```json
   "state_variants": {
     "door_open": "stands ajar, revealing the passage beyond",
     "door_closed": "blocks the way with its weathered planks",
     "in_inventory": "a reassuring weight at your side"
   }
   ```
3. **atmosphere** — Mood keywords: `"imposing, mysterious, guarded"`

The crucial observation: **these fragments are authored in game data, not generated by handlers**. The engine retrieves them unchanged and passes them to the LLM for weaving.

This pattern can be extended to cover action results, failures, NPC behaviors, environmental effects, etc. — all as **pre-authored fragments in game data** that the engine looks up and includes in the JSON, without any string interpolation or prose generation.

---

## Current Architecture (Post-Refactor)

After the ongoing refactor completes, handlers return:

```python
HandlerResult(
    success=True,
    primary="You pick up the rusty sword.",
    beats=["You step down from the table."],
    data={...}
)
```

The engine assembles a `NarrationPlan`:

```json
{
  "primary_text": "You pick up the rusty sword.",
  "secondary_beats": ["You step down from the table."],
  "entity_refs": {
    "item_sword": {
      "name": "rusty sword",
      "traits": ["pitted blade", "leather-wrapped hilt"]
    }
  },
  "viewpoint": {...},
  "scope": {...}
}
```

The LLM's job: **enhance and weave** existing prose with traits and beats.

---

## Proposed Architecture

Handlers return structured data only:

```python
HandlerResult(
    success=True,
    action=ActionReport(
        verb="take",
        object={"id": "item_sword", "name": "rusty sword"},
        outcome="success"
    ),
    effects=[
        {"type": "position_change", "action": "step_down", "from": "item_table"}
    ],
    data={...}
)
```

The engine assembles a `NarrationPlan`:

```json
{
  "action": {
    "verb": "take",
    "object": {"name": "rusty sword"},
    "outcome": "success"
  },
  "effects": [
    {"type": "position_change", "action": "step_down", "from_name": "wooden table"}
  ],
  "entity_refs": {
    "item_sword": {
      "name": "rusty sword",
      "traits": ["pitted blade", "leather-wrapped hilt"]
    }
  }
}
```

The LLM's job: **generate all prose** from structure.

Expected output: *"Stepping down from the table, you pick up the rusty sword. Its pitted blade feels heavier than expected."*

---

## Revised Proposal: Fragment-Centric Architecture

Instead of requiring the LLM to synthesize prose from pure structure (which may strain a 3B model), we extend the existing fragment pattern. **Fragments are authored in game data; the engine retrieves and places them in JSON; the LLM weaves them into prose.**

### Fragment Sources in Game Data

Extend `llm_context` to include action-related fragments. To achieve **combinatorial variety**, fragments are organized as pools with **core** (required) and **color** (optional embellishment) components:

```json
{
  "id": "item_sword",
  "name": "sword",
  "llm_context": {
    "traits": ["pitted blade", "leather-wrapped hilt", "still holds an edge",
               "notches from past battles", "faint maker's mark"],

    "state_variants": {
      "in_location": [
        "lies forgotten on the dusty floor",
        "rests against the wall",
        "glints in the dim light"
      ],
      "in_inventory": [
        "a reassuring weight at your side",
        "secure in your grip",
        "ready for whatever comes"
      ]
    },

    "action_fragments": {
      "take": {
        "core": [
          "you claim the blade",
          "you pick up the sword",
          "the sword is yours"
        ],
        "color": [
          "its weight settles into your grip",
          "rust flakes onto your palm",
          "the leather creaks as you grasp it",
          "it feels right in your hand",
          "balanced for combat"
        ]
      },
      "drop": {
        "core": [
          "you set aside the weapon",
          "you release the blade",
          "you put down the sword"
        ],
        "color": [
          "reluctantly",
          "with care",
          "it clatters on the stone"
        ]
      },
      "examine": {
        "core": [
          "you study the blade closely",
          "you inspect the weapon",
          "you look it over"
        ],
        "color": [
          "despite the rust, still deadly",
          "old blood stains the guard",
          "the edge remains keen"
        ]
      }
    },

    "failure_fragments": {
      "too_heavy": {
        "core": ["refuses to budge", "won't move"],
        "color": ["no matter how you strain", "it's fixed firmly"]
      }
    }
  }
}
```

**Combinatorial variety:** With 3 cores × 5 colors × 3 state variants = 45+ unique combinations for a single "take sword" action, plus trait variation.

For behaviors (NPCs, environmental effects, etc.):

```json
{
  "id": "actor_merchant",
  "llm_context": {
    "traits": ["weathered face", "keen eyes", "calloused hands",
               "silver-streaked beard", "ink-stained fingers"],

    "behavior_fragments": {
      "accept_gift": {
        "core": ["nods appreciatively", "accepts with a smile"],
        "color": ["eyes brightening", "weighing it in calloused hands"]
      },
      "reject_gift": {
        "core": ["waves a hand dismissively", "shakes head"],
        "color": ["barely glancing at it", "with a snort"]
      },
      "attack": {
        "core": ["lunges with surprising speed", "strikes without warning"],
        "color": ["eyes gone cold", "merchant's facade dropping"]
      }
    },

    "dialogue_fragments": {
      "greeting": [
        "'Welcome, traveler.'",
        "'Ah, a customer!'",
        "'What brings you to my shop?'"
      ],
      "thanks": [
        "'You have my gratitude.'",
        "'Most generous of you.'",
        "'I won't forget this.'"
      ]
    }
  }
}
```

For environmental effects:

```json
{
  "id": "loc_frozen_cavern",
  "llm_context": {
    "traits": ["ice-slicked walls", "breath visible in air",
               "frost patterns on stone", "icicles overhead"],

    "effect_fragments": {
      "cold_damage": {
        "core": ["the cold bites into your bones", "you shiver uncontrollably"],
        "color": ["fingers going numb", "teeth chattering"]
      },
      "hypothermia_warning": {
        "core": ["your fingers grow numb", "the cold seeps deeper"],
        "color": ["thoughts slowing", "limbs heavy"]
      },
      "warming": {
        "core": ["blessed warmth returns", "the chill recedes"],
        "color": ["feeling returning to your extremities", "you stop shivering"]
      }
    }
  }
}
```

### Engine Responsibility

The engine:
1. Determines what happened (action, outcome, effects)
2. **Randomly selects** from fragment pools:
   - 1 core fragment (required)
   - 1-2 color fragments (optional embellishment)
   - 1 state variant
   - 3-5 traits (shuffled order)
3. Passes structured data + selected fragments to LLM

**Selection rules:**

| Fragment Type | Pool Size | Engine Selects | LLM Uses |
|--------------|-----------|----------------|----------|
| action core | 2-4 | 1 | Must use |
| action color | 3-6 | 1-2 | Should weave in |
| state variant | 2-4 | 1 | Must use |
| traits | 10-25 | 3-5 (shuffled) | Pick what fits |
| effect core | 2-3 | 1 | Must use |
| effect color | 2-4 | 0-1 | May use |

**Crucially: the engine never edits or interpolates the fragments. It only selects and places them.**

### What the LLM Receives

```json
{
  "action": {
    "verb": "take",
    "object": "sword",
    "outcome": "success"
  },
  "fragments": {
    "action_core": "you claim the blade",
    "action_color": ["rust flakes onto your palm"],
    "new_state": "a reassuring weight at your side"
  },
  "effects": [
    {
      "type": "position_change",
      "core": "stepping down from the worn table",
      "color": "its surface creaking"
    }
  ],
  "entity_refs": {
    "item_sword": {
      "name": "rusty sword",
      "traits": ["pitted blade", "leather-wrapped hilt", "notches from past battles"]
    }
  }
}
```

**Possible outputs** (same action, different random selections):

1. *"Stepping down from the worn table, you claim the blade. Rust flakes onto your palm as the rusty sword becomes a reassuring weight at your side."*

2. *"You pick up the sword, the leather creaking as you grasp it. Its pitted blade, notched from past battles, is now secure in your grip."*

3. *"The sword is yours. Its weight settles into your grip, balanced for combat. The rusty blade rests ready at your side."*

Each playthrough produces different narration from the same action.

### Advantages of Fragment-Centric Approach

1. **Combinatorial variety** — core × color × state × traits = many unique outputs per action
2. **Reduces LLM reasoning load** — Fragments provide sentence-level building blocks, not just structure
3. **Preserves author voice** — Game author writes the evocative phrases
4. **Consistent with existing pattern** — Extends `traits` and `state_variants` already in use
5. **Simpler prompt** — LLM weaves fragments rather than generating from scratch
6. **Handler code simplifies** — Returns structure; fragments come from data
7. **Still achieves separation** — No prose generation in handler code
8. **Localization-friendly** — Fragments can be translated per-language
9. **Replay value** — Same actions produce fresh narration on each playthrough

### What Handlers Return

Handlers return pure structure. Fragment selection is performed by the engine:

```python
HandlerResult(
    success=True,
    action=ActionReport(
        verb="take",
        object_id="item_sword",
        outcome="success"
    ),
    effects=[
        EffectReport(type="position_change", detail="step_down", from_id="item_table")
    ]
)
```

The engine's `FragmentResolver`:
1. Looks up `item_sword.llm_context.action_fragments.take`
2. Randomly selects 1 from `core` pool → `"you claim the blade"`
3. Randomly selects 1-2 from `color` pool → `["rust flakes onto your palm"]`
4. Randomly selects 1 from `state_variants.in_inventory` → `"a reassuring weight at your side"`
5. Shuffles and selects 3-5 from `traits`

### Fallback for Missing Fragments

If a fragment pool is missing or empty, the engine uses generic defaults:
- Action core: `"you take the {name}"`
- Action color: (empty — no color added)
- State variant: `"you have the {name}"`
- Failure core: `"that doesn't work"`
- Effect core: `"you move"`

Defaults are defined in a single place (not per-handler). Game authors are encouraged to provide entity-specific fragments for richer narration, but the system works without them.

### Fragment Pool Sizing Guidelines

| Fragment Type | Minimum | Recommended | Purpose |
|--------------|---------|-------------|---------|
| action core | 2 | 3-4 | Variety in base action description |
| action color | 2 | 4-6 | Sensory/emotional embellishment |
| state variant | 2 | 3-4 | How entity feels in new state |
| failure core | 1 | 2-3 | How the failure manifests |
| failure color | 0 | 2-3 | Additional failure detail |
| traits | 5 | 15-25 | Atmospheric details (existing pattern) |

More fragments = more variety. The engine always selects a small subset per turn, so large pools don't burden the LLM.

---

## Benefits

1. **Clean separation of concerns**
   - Engine: computes facts and state changes
   - LLM: produces all natural language
   - No prose logic in handler code

2. **Style consistency**
   - All prose originates from a single source (LLM + style prompt)
   - No mixing of handler prose style with LLM enhancement

3. **Localization potential**
   - Structured data can be rendered in any language
   - No embedded English in handler code

4. **Trait-first narration**
   - Traits become primary descriptive content
   - More variety in descriptions

5. **Simpler handler code**
   - Handlers return data, not prose
   - Easier to test and maintain

---

## Challenges

### 1. Small Model Capability (Mitigated by Fragments)

With the fragment-centric approach, the LLM's task is simpler:

**Pure structure (harder):**
- Input: `{verb: "take", object: {name: "sword"}}`
- Output: Generate prose from scratch

**Fragment-centric (easier):**
- Input: `{verb: "take", fragments: {action: "you claim the blade", state: "a reassuring weight"}}`
- Output: Weave provided fragments with traits

The fragment approach reduces cognitive load — the LLM arranges and connects authored phrases rather than inventing them.

### 2. Fragment Authoring Burden

Game authors must provide fragments for:
- Action results per verb (take, drop, open, close, etc.)
- Failure reasons per entity
- NPC behaviors (combat, trade, dialogue)
- Environmental effects

**Mitigation:**
- Generic defaults for common cases
- Fragment templates in documentation
- Tooling to identify missing fragments

### 3. Fragment Key Vocabulary

Need consistent keys across all entities:
- Action verbs: `take`, `drop`, `open`, `close`, `lock`, `unlock`, `read`, `push`, `pull`, `attack`, `give`, `examine`, `climb`, `enter`, `light`, `extinguish`
- Failure reasons: `too_heavy`, `not_portable`, `locked`, `not_visible`, `already_open`, `already_closed`, `no_key`, `wrong_key`, `not_container`, `inventory_full`
- Effect types: `step_up`, `step_down`, `enter`, `exit`, `state_change`

This vocabulary must be documented and enforced.

### 4. Compound Actions

Some actions involve multiple steps. With fragments:

```json
{
  "action": {"verb": "unlock_and_open", "outcome": "success"},
  "fragments": {
    "phase_1": "the key turns with a satisfying click",
    "phase_2": "the chest lid swings open"
  }
}
```

The LLM combines: *"The key turns with a satisfying click, and the chest lid swings open."*

### 5. Dynamic Content

Some content requires entity names or counts that can't be pre-authored:
- "You give the sword to the merchant" — two entity names
- "The chest contains 5 gold coins" — count

**Solution:** Allow placeholder tokens in fragments that the engine fills:
```json
"action_fragments": {
  "give": "you hand over the {item}"
}
```

The engine performs this minimal substitution. More complex interpolation (pluralization, article selection) should be avoided — keep the fragments as complete as possible.

### 6. Dialogue and Special Content

Dialogue is naturally a fragment:
```json
"dialogue_fragments": {
  "greeting": "'Welcome to my shop, traveler.'",
  "thanks": "'You have my gratitude.'"
}
```

For `read` actions, the text content is a fragment:
```json
"properties": {
  "text": "Beware the wolf in the northern woods."
}
```

The engine passes this as a fragment; no special handling needed.

---

## Proposed Type Definitions

```python
class ActionReport(TypedDict, total=False):
    verb: str                          # Canonical verb
    subject: Optional[EntityRef]       # Usually player (implicit)
    object: Optional[EntityRef]        # Direct object
    indirect_object: Optional[EntityRef]  # "give X to Y"
    instrument: Optional[EntityRef]    # "unlock X with Y"
    outcome: Literal["success", "failure"]
    failure_reason: Optional[str]      # Code like "locked", "too_heavy"

class EffectReport(TypedDict, total=False):
    type: Literal["position_change", "state_change", "inventory_change"]
    action: str                        # "step_down", "step_up", "open", "close"
    target_name: Optional[str]         # Human-readable name
    from_name: Optional[str]           # For position changes

class ExitReport(TypedDict):
    direction: str
    destination_name: str
    passage_type: Optional[str]        # "stairs", "passage", "door"
    state: Optional[Literal["open", "closed", "locked"]]

class NarrationPlan(TypedDict, total=False):
    action: ActionReport
    effects: list[EffectReport]
    viewpoint: ViewpointInfo
    scope: ScopeInfo
    entity_refs: dict[str, EntityRef]
    exits: list[ExitReport]            # Replaces must_mention.exits_text
    text_fragment: Optional[str]       # For dialogue, read content, etc.
```

---

## Prompt Changes Required

Section A of the prompt would need revision to support fragment weaving:

### Current Rendering Rules
```
1. Use `primary_text` as the core of narration
2. For `full` verbosity, weave in `secondary_beats` naturally
3. Use traits from `entity_refs` to add sensory detail
```

### Proposed Rendering Rules

```
FRAGMENT WEAVING RULES

The engine provides pre-selected fragments. Your job is to weave them
into natural prose.

1. REQUIRED fragments (must appear):
   - fragments.action_core — the core action statement
   - fragments.new_state — how the entity is after the action
   - effects[].core — any effect statements

2. OPTIONAL fragments (weave in naturally):
   - fragments.action_color — embellishment for the action
   - effects[].color — embellishment for effects
   - entity_refs[].traits — sensory details

3. WEAVING GUIDELINES:
   - Combine fragments into flowing sentences
   - Use traits to add texture and atmosphere
   - Never list fragments mechanically
   - Vary sentence structure
   - Connect fragments with natural transitions

4. EXAMPLES:

   Input:
   {
     "fragments": {
       "action_core": "you claim the blade",
       "action_color": ["rust flakes onto your palm"],
       "new_state": "a reassuring weight at your side"
     },
     "entity_refs": {
       "item_sword": {"traits": ["pitted blade", "leather-wrapped hilt"]}
     }
   }

   Good output:
   "You claim the blade, rust flaking onto your palm. The pitted steel
    is a reassuring weight at your side."

   Bad output (mechanical listing):
   "You claim the blade. Rust flakes onto your palm. Pitted blade.
    Leather-wrapped hilt. A reassuring weight at your side."
```

This approach is simpler than the pure-structure prompt because the LLM doesn't need to generate action descriptions from templates — it weaves pre-authored fragments.

---

## Experiment Plan

### Goal

Determine whether a 3B model can generate quality prose from structured data + fragments with acceptable latency.

### Metrics

1. **Prose quality** — Natural? Grammatical? Good flow between fragments?
2. **Latency** — Acceptable for interactive play? (Target: <2s per turn)
3. **Consistency** — Reliable weaving of fragments? Follows instructions?
4. **Fragment integration** — Connects fragments smoothly? Incorporates traits naturally?

### Experiment Phases

#### Phase 1: Baseline Measurement

**Objective:** Establish current performance baseline.

**Tasks:**
1. Select 10 representative commands spanning action types:
   - Movement: `go north`, `climb tree`, `enter cave`
   - Manipulation: `take sword`, `drop key`, `put gem in chest`
   - Interaction: `open door`, `unlock chest with key`, `read note`
   - Observation: `look`, `examine sword`
   - Failure cases: `take table` (too heavy), `open chest` (locked)

2. Run each command through current system with LLM narrator
3. Record: output text, latency, token count

**Deliverable:** Baseline metrics spreadsheet

#### Phase 2: Fragment-Centric Prompt Prototype

**Objective:** Create and test a fragment-weaving prompt.

**Tasks:**
1. Create `experimental_fragment_prompt.txt` with:
   - Fragment weaving rules
   - Trait incorporation guidelines
   - Examples of fragments + structure → prose

2. Author fragments for the 10 test commands in a test JSON file:
   - Add `action_fragments` to relevant items
   - Add `failure_fragments` for failure cases
   - Add `effect_fragments` for positioning changes

3. Design the structured JSON format for each command

4. Test prompt directly with model (bypass game engine):
   - Feed fragments + structure + prompt to model
   - Record output quality and latency

**Deliverable:** Prototype prompt, test fragments, quality assessment

#### Phase 3: Engine Prototype

**Objective:** Implement fragment lookup in the engine.

**Tasks:**
1. Extend `llm_context` schema to support new fragment types:
   - `action_fragments`
   - `failure_fragments`
   - `effect_fragments`
   - `behavior_fragments`

2. Create `FragmentResolver` module that:
   - Looks up fragments by verb/reason/effect type
   - Returns generic default if fragment missing
   - Handles minimal placeholder substitution

3. Modify `NarrationAssembler` to:
   - Call `FragmentResolver` for relevant fragments
   - Include fragments in `NarrationPlan`

4. Update `fancy_game` entities with sample fragments

5. Run through full system with prototype prompt

**Deliverable:** Working prototype with fragment lookup

#### Phase 4: Comparative Evaluation

**Objective:** Compare fragment-centric vs. current approach.

**Tasks:**
1. Run same 10 commands through both systems
2. Evaluate output quality:
   - Does fragment weaving produce natural prose?
   - Are transitions between fragments smooth?
   - Are traits incorporated well?
3. Compare latency measurements
4. Document any failure patterns

**Evaluation Criteria:**
- Quality: Is output at least as good as current?
- Latency: Is output within 20% of current?
- Reliability: Does model weave fragments consistently?

**Deliverable:** Comparison report with recommendation

#### Phase 5: Decision Point

Based on Phase 4 results:

**If successful:**
- Proceed with full migration:
  - Handler refactor to return structure
  - Fragment authoring guidelines
  - Schema updates for fragment types
- Estimate effort for remaining handlers
- Update implementation plan

**If marginal:**
- Identify specific problem areas
- Consider which action types work well vs. poorly
- Adjust fragment granularity (more/less detailed)

**If unsuccessful:**
- Document failure modes
- Archive experiment
- Continue with current prose-based approach

#### Phase 6 (if proceeding): Full Migration

**Tasks:**
1. Define complete fragment vocabulary (verbs, failures, effects)
2. Update all game JSON with fragments
3. Refactor all handlers to return structure
4. Update prompts
5. Comprehensive testing

---

## Hybrid Alternative

If full structure proves too challenging for the 3B model, consider a hybrid:

1. **Simple actions** (take, drop, open, close): Structured
2. **Complex actions** (multi-step, conditional): Prose fragments
3. **Dialogue and special content**: Text fragments

This gets some benefits (cleaner simple handlers, consistent simple actions) while keeping prose for complex cases.

---

## Estimated Effort

| Phase | Tasks | Effort |
|-------|-------|--------|
| Phase 1: Baseline | Measure current performance | Small |
| Phase 2: Prompt | Design structured prompt | Medium |
| Phase 3: Prototype | Modify 3-4 handlers | Medium |
| Phase 4: Evaluation | Run comparison | Small |
| Phase 5: Decision | Analyze and decide | Small |

Total experiment: Medium effort, mostly prompt design and testing.

Full migration (if approved): Large effort — all handlers need restructuring.

---

## Open Questions

1. **Verb vocabulary size:** How many canonical verbs? Current handlers use many synonyms.
   - Proposal: Map all synonyms to ~20 canonical verbs

2. **Failure reason vocabulary:** How many distinct failure reasons?
   - Proposal: Start with ~15, expand as needed

3. **Effect vocabulary:** How many effect types and actions?
   - Proposal: ~5 types, ~10 actions each

4. **Fallback mechanism:** What if model produces bad output?
   - Current: Handler prose is always valid fallback
   - Proposed: Need structured fallback or retry logic

5. **Testing strategy:** How to test structured handlers?
   - Unit tests verify structure, not prose
   - Integration tests verify LLM produces valid prose

---

## Conclusion

The fragment-centric approach with combinatorial selection offers compelling benefits:

1. **High variety from authored content** — core × color × state × traits = dozens of unique outputs per action
2. **Achieves clean separation** — Handlers return structure, not prose
3. **Reduces LLM burden** — Weaving pre-selected fragments is easier than generating from scratch
4. **Preserves author voice** — Evocative phrases are authored, not generated
5. **Extends existing pattern** — Builds on `traits` and `state_variants` already in use
6. **Enables localization** — Fragment pools can be translated; structure is universal
7. **Replay value** — Same actions produce fresh narration on each playthrough

The key insight is that fragments already work well in the current system (traits, state_variants). Extending this pattern to actions, failures, and behaviors — with pools for combinatorial selection — is a natural evolution that achieves variety without burdening the 3B model.

### Key Success Factors

1. **Well-designed fragment vocabulary** — Consistent keys for verbs, failures, effects
2. **Rich fragment pools** — 3-4 core + 4-6 color per action for good variety
3. **Smart defaults** — Generic fallbacks for missing fragments
4. **Clear prompt instructions** — Required vs. optional fragments, weaving guidelines
5. **Minimal interpolation** — Fragments should be as complete as possible

### Recommendation

Proceed with experiment phases 1-4 to validate that fragment weaving works well with the 3B model. The experiment can be done largely independently of the main codebase by testing prompts directly with sample JSON.

If successful, the migration path is clear:
1. Extend `llm_context` schema with core/color structure
2. Author fragment pools for game entities
3. Implement `FragmentResolver` with random selection
4. Refactor handlers to return structure
5. Update prompts for fragment weaving
